/**
 * Documentary Puzzle Studio â€” Production Pipeline Hook
 *
 * âœ… WITH TEST MODE INTEGRATION
 *
 * ÙØ§Ù†Ú©Ø´Ù† Ø§ØµÙ„ÛŒ: processPipelineItem
 *   SCAN â†’ NARRATIVE â†’ IMAGES (batch) â†’ MUSIC â†’ METADATA â†’ READY
 *
 * ğŸ§ª TEST MODE: Ø¨Ø§ÛŒâ€ŒÙ¾Ø³ Ú©Ø±Ø¯Ù† ØªÙ…Ø§Ù… AI calls Ùˆ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¢Ù…Ø§Ø¯Ù‡
 */

import React, { useState, useCallback, useEffect, useRef } from "react";
import {
  PieceShape,
  PieceMaterial,
  MovementType,
  UserPreferences,
  ReconstructionGenre,
  MasterVisualStyle,
  NarrativeLens,
  DocumentaryProject,
  ProjectStatus,
  ChapterStatus,
  StoryArc,
  MusicMood,
  Chapter,
  calcChapterCount,
  assignChapterRoles,
  getChapterComplexity,
  getChapterTransition,
  getPieceCountForComplexity,
} from "../types";
import { generateDocumentaryNarrative, detectMusicMoodFromTopic } from "../services/ai/narrativeEngine";
import { generateChapterImages } from "../services/ai/artGeneration";
import { BatchProgressEvent, DocumentaryMetadata, ChapterMarker } from "../services/types/serviceTypes";
import { MusicTrack } from "../components/sidebar/MusicUploader";
import { contentApi, ContentPayload } from "../services/api/contentApi";
import { sonicEngine } from "../services/proceduralAudio";
import { getJalaliDate } from "../utils/dateUtils";
import { getFolderFromMood } from "../services/ai/musicSelection";
import { useTestMode } from "../contexts/TestModeContext";
import { TEST_PROJECTS } from "../utils/testModeData";

// â”€â”€â”€ TYPES â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

// â”€â”€â”€ HELPER: RANDOM PUZZLE CONFIG â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

/**
 * ØªÙˆÙ„ÛŒØ¯ Ú©Ø§Ù†ÙÛŒÚ¯ ØªØµØ§Ø¯ÙÛŒ Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ù¾Ø§Ø²Ù„
 * Ù‡Ø± ÙØµÙ„ ÛŒÚ© Shape, Material, Ùˆ Movement Ø±Ù†Ø¯ÙˆÙ… Ø¯Ø±ÛŒØ§ÙØª Ù…ÛŒâ€ŒÚ©Ù†Ø¯
 */
const generateRandomPuzzleConfig = (pieceCount: number, complexity: "easy" | "medium" | "hard") => {
  const shapes: PieceShape[] = [PieceShape.SQUARE, PieceShape.HEXAGON, PieceShape.JIGSAW, PieceShape.BRICK];

  const materials: PieceMaterial[] = [
    PieceMaterial.CARDBOARD,
    PieceMaterial.WOOD,
    PieceMaterial.GLASS,
    PieceMaterial.CARBON,
  ];

  const movements: MovementType[] = [
    MovementType.STANDARD,
    MovementType.FLIGHT,
    MovementType.WAVE,
    MovementType.VORTEX,
    MovementType.ELASTIC,
    MovementType.PLAYFUL,
  ];

  return {
    pieceCount,
    shape: shapes[Math.floor(Math.random() * shapes.length)],
    material: materials[Math.floor(Math.random() * materials.length)],
    movement: movements[Math.floor(Math.random() * movements.length)],
    complexityLevel: complexity,
  };
};

export type PipelineStep =
  | "IDLE"
  | "SCAN"
  | "NARRATIVE"
  | "IMAGES"
  | "MUSIC"
  | "METADATA"
  | "READY"
  | "RECORDING"
  | "PACKAGING";

export interface ProductionStep {
  id: string;
  label: string;
  status: "pending" | "in_progress" | "completed" | "error";
  details?: string;
}

export interface DocumentaryQueueItem {
  genre: ReconstructionGenre;
  topic: string;
  narrativeLens: NarrativeLens;
  masterVisualStyle: MasterVisualStyle;
  targetDurationMinutes: number;
}

export interface PipelineState {
  project: DocumentaryProject | null;
  currentChapterIndex: number;
  isGenerating: boolean;
  isSolving: boolean;
  isRecording: boolean;
  progress: number;
  error: string | null;
  audioError: boolean;
  isAutoMode: boolean;
  isFullPackage: boolean;
  queue: DocumentaryQueueItem[];
  currentQueueIdx: number;
  pipelineStep: PipelineStep;
  productionSteps: ProductionStep[];
  storyArc: StoryArc | null;
  docSnippets: string[];
  lastVideoBlob: Blob | null;
  thumbnailDataUrl: string | null;
}

// â”€â”€â”€ CLOUDFLARE PROXY â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

const CLOUDFLARE_WORKER_URL = "https://plain-tooth-75c3.jujube-bros.workers.dev/";

// â”€â”€â”€ AUDIO HELPERS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

const decodeAndStoreMusicBuffer = async (
  audioRef: React.RefObject<HTMLAudioElement | null>,
  musicBufferRef: React.MutableRefObject<AudioBuffer | null>,
  blobOrNull?: Blob | null,
): Promise<void> => {
  const ctx = sonicEngine.getContext();
  if (!ctx) {
    console.warn("âš ï¸ [MUSIC] No AudioContext for decode");
    return;
  }

  let arrayBuffer: ArrayBuffer;
  if (blobOrNull && blobOrNull.size > 0 && !blobOrNull.type.startsWith("text/")) {
    try {
      arrayBuffer = await blobOrNull.arrayBuffer();
    } catch (e) {
      console.warn("âš ï¸ [MUSIC] Blob.arrayBuffer() failed:", e);
      return;
    }
  } else {
    const el = audioRef.current;
    const url = el?.src || el?.currentSrc;
    if (!url || url === "" || url === "about:blank") return;
    try {
      const res = await fetch(url);
      if (!res.ok) throw new Error(`Fetch ${res.status}`);
      const blob = await res.blob();
      if (blob.size === 0 || blob.type.startsWith("text/")) {
        console.warn(`âš ï¸ [MUSIC] Fetched response is not audio (size=${blob.size}, type=${blob.type})`);
        return;
      }
      arrayBuffer = await blob.arrayBuffer();
    } catch (e) {
      console.warn("âš ï¸ [MUSIC] Fetch for decode failed:", e);
      return;
    }
  }

  try {
    const decoded = await ctx.decodeAudioData(arrayBuffer.slice(0));
    musicBufferRef.current = decoded;
    console.log(`ğŸµ [MUSIC] Decoded to AudioBuffer (${(decoded.length / decoded.sampleRate).toFixed(1)}s)`);
  } catch (e) {
    console.warn("âš ï¸ [MUSIC] Decode failed (keeping previous buffer):", e);
  }
};

// â”€â”€â”€ SMART MUSIC â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

interface SmartMusicParams {
  musicTracks: MusicTrack[];
  mood: MusicMood;
  topic: string;
  fetchAudioBlob: (url: string) => Promise<{ url: string; blob: Blob } | null>;
  onAddCloudTrack: (url: string, title: string, source?: "backend" | "ai") => void;
  setActiveTrackName: (name: string | null) => void;
  audioRef: React.RefObject<HTMLAudioElement | null>;
}

const selectSmartMusic = async (
  params: SmartMusicParams,
): Promise<{ source: string; title: string; blob?: Blob } | null> => {
  const { musicTracks, mood, topic, fetchAudioBlob, onAddCloudTrack, setActiveTrackName, audioRef } = params;

  const manual = musicTracks.filter((t) => t.source === "manual");
  if (manual.length > 0) {
    const track = manual[0];
    if (audioRef.current) {
      audioRef.current.src = track.url;
      audioRef.current.load();
    }
    setActiveTrackName(track.name);
    console.log(`ğŸµ [MUSIC] Manual: ${track.name}`);
    return { source: "Manual Upload", title: track.name };
  }

  let trackData: { title: string; url: string; source: string } | null = null;
  try {
    const { assetApi } = await import("../services/api/assetApi");
    const folderName = getFolderFromMood(mood);
    console.log(`ğŸµ [MUSIC] Backend search: folder=${folderName}`);
    const backendUrl = await assetApi.getRandomMusicByMood(folderName);
    if (backendUrl) trackData = { title: `${mood} (Database)`, url: backendUrl, source: "Backend Database" };

    if (!trackData) {
      const fallback = await assetApi.getRandomMusicByMood("calm");
      if (fallback) trackData = { title: "Calm (Fallback)", url: fallback, source: "Backend Database" };
    }
  } catch (e) {
    console.warn("âš ï¸ [MUSIC] Backend search failed:", e);
  }

  if (!trackData) {
    try {
      const { findSmartMusicByMood } = await import("../services/geminiService");
      trackData = await findSmartMusicByMood(mood, topic);
    } catch (e) {
      console.warn("âš ï¸ [MUSIC] AI search failed:", e);
    }
  }

  if (trackData?.url) {
    const result = await fetchAudioBlob(trackData.url);
    if (result) {
      const sourceType = trackData.source === "Backend Database" ? "backend" : "ai";
      onAddCloudTrack(result.url, trackData.title, sourceType);
      setActiveTrackName(trackData.title);
      if (audioRef.current) {
        audioRef.current.src = result.url;
        audioRef.current.load();
      }
      console.log(`ğŸµ [MUSIC] Selected: ${trackData.title}`);
      return { source: trackData.source, title: trackData.title, blob: result.blob };
    }
  }

  console.warn("âš ï¸ [MUSIC] No music found");
  return null;
};

// â”€â”€â”€ CHAPTER MARKERS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

const buildChapterMarkers = (chapters: Chapter[]): ChapterMarker[] => {
  let totalSeconds = 0;
  return chapters.map((ch) => {
    const mins = Math.floor(totalSeconds / 60);
    const secs = totalSeconds % 60;
    const timestamp = `${mins}:${secs.toString().padStart(2, "0")}`;
    totalSeconds += ch.durationSeconds;
    return { timestamp, title: ch.title };
  });
};

// â”€â”€â”€ METADATA BUILDER â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

const buildDocumentaryMetadata = (
  project: DocumentaryProject,
  thumbnailUrl?: string,
): DocumentaryMetadata => {
  const markers = buildChapterMarkers(project.chapters);
  const chapterList = project.chapters.map((ch, i) => `ÙØµÙ„ ${i + 1}: ${ch.title}`).join("\n");

  // âœ… Build full script with all chapter narratives
  const fullScript = project.chapters
    .map((ch, i) => {
      return `
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ÙØµÙ„ ${i + 1}: ${ch.title}
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

${ch.narrativeText || ""}

Ù…Ø¯Øª Ø²Ù…Ø§Ù†: ${ch.duration} Ø«Ø§Ù†ÛŒÙ‡
`.trim();
    })
    .join("\n\n");

  return {
    title: `ğŸ” ${project.topic} â€” ${project.genre} Documentary`,
    description: `ÛŒÚ© documentary ${project.targetDurationMinutes}-Ø¯Ù‚ÛŒÙ‚Ù‡â€ŒØ§ÛŒ Ø¯Ø±Ø¨Ø§Ø±Ù‡ ${project.topic}

ğŸ“š ÙØµÙ„â€ŒÙ‡Ø§:
${chapterList}

ğŸ¬ Auto-generated by Documentary Puzzle Studio
ğŸ“¹ Total Chapters: ${project.chapters.length}
â±ï¸ Duration: ${project.targetDurationMinutes} minutes`,
    tags: [project.genre, project.topic, "documentary", "puzzle", "history", "mystery", "longform"],
    hashtags: ["#documentary", "#puzzle", "#mystery", "#longform", "#history"],
    ctr_strategy: `Ø¹Ù†ÙˆØ§Ù† Ø´ÙˆÚ©â€ŒØ¯Ù‡Ù†Ø¯Ù‡ + ÙØµÙ„â€ŒØ¨Ù†Ø¯ÛŒ ÙˆØ§Ø¶Ø­ + chapter markers`,
    chapterMarkers: markers,
    fullScript, // âœ… Ø³Ù†Ø§Ø±ÛŒÙˆ Ú©Ø§Ù…Ù„
    thumbnailUrl, // âœ… thumbnail URL
  };
};

// â”€â”€â”€ HOOK â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

export const useProductionPipeline = (
  preferences: UserPreferences,
  setPreferences: React.Dispatch<React.SetStateAction<UserPreferences>>,
  musicTracks: MusicTrack[],
  selectedTrackId: string | null,
  setActiveTrackName: (name: string | null) => void,
  onAddCloudTrack: (url: string, title: string, source?: "backend" | "ai") => void,
  audioRef: React.RefObject<HTMLAudioElement | null>,
  musicBufferRef: React.MutableRefObject<AudioBuffer | null>,
) => {
  // âœ… TEST MODE HOOK
  const { isTestMode, selectedTestProject } = useTestMode();

  const [state, setState] = useState<PipelineState>({
    project: null,
    currentChapterIndex: 0,
    isGenerating: false,
    isSolving: false,
    isRecording: false,
    progress: 0,
    error: null,
    audioError: false,
    isAutoMode: false,
    isFullPackage: false,
    queue: [],
    currentQueueIdx: -1,
    pipelineStep: "IDLE",
    productionSteps: [],
    storyArc: null,
    docSnippets: [],
    lastVideoBlob: null,
    thumbnailDataUrl: null,
  });

  const [metadata, setMetadata] = useState<DocumentaryMetadata | null>(null);
  const [isMetadataLoading, setIsMetadataLoading] = useState(false);
  const isExportingRef = useRef(false);

  // â”€â”€â”€ STEP HELPERS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

  const updateProductionStep = useCallback(
    (stepId: string, status: ProductionStep["status"], details?: string) => {
      setState((prev) => {
        const idx = prev.productionSteps.findIndex((s) => s.id === stepId);
        if (idx >= 0) {
          const steps = [...prev.productionSteps];
          steps[idx] = { ...steps[idx], status, details: details || steps[idx].details };
          return { ...prev, productionSteps: steps };
        }
        return {
          ...prev,
          productionSteps: [...prev.productionSteps, { id: stepId, label: stepId, status, details }],
        };
      });
    },
    [],
  );

  const initProductionSteps = useCallback(() => {
    setState((prev) => ({
      ...prev,
      productionSteps: [
        { id: "ğŸ“Š SCAN", label: "Ø´Ø±ÙˆØ¹ Ù¾Ø±ÙˆÚ˜Ù‡", status: "pending" },
        { id: "ğŸ“– NARRATIVE", label: "ØªÙˆÙ„ÛŒØ¯ Ø±ÙˆØ§ÛŒØª ÙØµÙ„â€ŒÙ‡Ø§", status: "pending" },
        { id: "ğŸ–¼ï¸ IMAGES", label: "ØªÙˆÙ„ÛŒØ¯ ØªØµØ§ÙˆÛŒØ± batch", status: "pending" },
        { id: "ğŸµ MUSIC", label: "Ø§Ù†ØªØ®Ø§Ø¨ Ù…ÙˆØ³ÛŒÙ‚ÛŒ", status: "pending" },
        { id: "ğŸ“ METADATA", label: "Ù…ØªØ§Ø¯ÛŒØªØ§ Ùˆ ÙØµÙ„â€ŒØ¨Ù†Ø¯ÛŒ", status: "pending" },
        { id: "ğŸ¬ READY", label: "Ø¢Ù…Ø§Ø¯Ù‡ Ù¾Ø®Ø´", status: "pending" },
        { id: "ğŸ¥ RECORD", label: "Ø¶Ø¨Ø· ÙˆÛŒØ¯Ø¦Ùˆ", status: "pending" },
        { id: "ğŸ“¦ PACKAGE", label: "Ø¯Ø§Ù†Ù„ÙˆØ¯ Ùˆ Ø°Ø®ÛŒØ±Ù‡", status: "pending" },
      ],
    }));
  }, []);

  // â”€â”€â”€ FETCH AUDIO BLOB â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

  const fetchAudioBlob = useCallback(async (url: string): Promise<{ url: string; blob: Blob } | null> => {
    const proxies = [
      `${CLOUDFLARE_WORKER_URL}?url=${encodeURIComponent(url)}`,
      `https://api.allorigins.win/raw?url=${encodeURIComponent(url)}`,
    ];
    for (const p of proxies) {
      try {
        const res = await fetch(p);
        if (res.ok) {
          let blob = await res.blob();
          if (!blob.type || blob.type === "application/octet-stream")
            blob = new Blob([blob], { type: "audio/mpeg" });
          console.log(`âœ… [fetchAudioBlob] size=${(blob.size / 1024).toFixed(1)}KB`);
          return { url: URL.createObjectURL(blob), blob };
        }
      } catch {
        /* next */
      }
    }
    console.error("âŒ [fetchAudioBlob] All proxies failed");
    return null;
  }, []);

  // â”€â”€â”€ DOWNLOAD â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

  const downloadFile = (name: string, blob: Blob) => {
    const url = URL.createObjectURL(blob);
    const link = document.createElement("a");
    link.href = url;
    link.download = name;
    document.body.appendChild(link);
    link.click();
    document.body.removeChild(link);
    setTimeout(() => URL.revokeObjectURL(url), 3000);
  };

  // â”€â”€â”€ PACKAGING â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

  const executePackaging = useCallback(
    async (videoBlob: Blob) => {
      if (isExportingRef.current) return;
      isExportingRef.current = true;

      const jalali = getJalaliDate();
      const cleanTitle = (metadata?.title || "Documentary").replace(/[\\/:*?"<>|]/g, "").slice(0, 50);
      const base = `${jalali}_${cleanTitle}`;

      updateProductionStep("ğŸ“¦ PACKAGE", "in_progress", "Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø´Ø±ÙˆØ¹ Ø´Ø¯...");

      try {
        // âœ… Download video
        downloadFile(`${base}_Video.${videoBlob.type.includes("mp4") ? "mp4" : "webm"}`, videoBlob);

        // âœ… Add thumbnail URL to metadata if available
        const completeMetadata = metadata
          ? {
              ...metadata,
              thumbnailUrl: state.thumbnailDataUrl || undefined,
            }
          : null;

        if (completeMetadata) {
          await new Promise((r) => setTimeout(r, 1500));
          const markerText = completeMetadata.chapterMarkers
            .map((m) => `${m.timestamp} - ${m.title}`)
            .join("\n");

          // âœ… Build complete metadata with full script
          let metadataContent = `TITLE: ${completeMetadata.title}

DESCRIPTION:
${completeMetadata.description}

CHAPTER MARKERS:
${markerText}

TAGS: ${completeMetadata.tags.join(", ")}

HASHTAGS: ${completeMetadata.hashtags.join(" ")}`;

          // âœ… Add thumbnail URL if available
          if (completeMetadata.thumbnailUrl) {
            metadataContent += `\n\nTHUMBNAIL URL:\n${completeMetadata.thumbnailUrl}`;
          }

          // âœ… Add full script if available
          if (completeMetadata.fullScript) {
            metadataContent += `\n\n${"=".repeat(70)}
FULL SCRIPT (14 CHAPTERS)
${"=".repeat(70)}

${completeMetadata.fullScript}`;
          }

          downloadFile(
            `${base}_Metadata.txt`,
            new Blob([metadataContent], { type: "text/plain; charset=utf-8" }),
          );
        }

        if (state.thumbnailDataUrl) {
          await new Promise((r) => setTimeout(r, 1500));
          const res = await fetch(state.thumbnailDataUrl);
          downloadFile(`${base}_Thumbnail.jpg`, await res.blob());
        }

        if (completeMetadata && state.project && state.storyArc) {
          try {
            const payload: ContentPayload = {
              jalaliDate: jalali,
              puzzleCard: {
                source: "DOCUMENTARY",
                category: state.project.genre,
                narrativeLens: state.project.narrativeLens,
                duration: state.project.targetDurationMinutes,
              },
              story: {
                coreSubject: state.project.topic,
                hook: state.storyArc.hook,
                buildup: state.storyArc.buildup,
                climax: state.storyArc.climax,
                reveal: state.storyArc.reveal,
                conclusion: state.storyArc.conclusion,
              },
              metadata: {
                title: completeMetadata.title,
                description: completeMetadata.description,
                tags: completeMetadata.tags,
                hashtags: completeMetadata.hashtags,
              },
              files: {
                videoFilename: `${base}_Video.${videoBlob.type.includes("mp4") ? "mp4" : "webm"}`,
                videoSizeMB: Number((videoBlob.size / 1024 / 1024).toFixed(2)),
              },
            };
            const result = await contentApi.saveContent(payload);
            if (result.success) {
              console.log(`âœ… [DB] Saved â€” ID: ${result.data?._id}`);
              updateProductionStep(
                "ğŸ“¦ PACKAGE",
                "completed",
                `Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯ â€” ID: ${result.data?._id?.substring(0, 8)}...`,
              );
            } else {
              updateProductionStep("ğŸ“¦ PACKAGE", "completed", "Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯ â€” Ø®Ø·Ø§ Ø¯Ø± Ø°Ø®ÛŒØ±Ù‡ DB");
            }
          } catch {
            updateProductionStep("ğŸ“¦ PACKAGE", "completed", "Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯ â€” DB skip");
          }
        } else {
          updateProductionStep("ğŸ“¦ PACKAGE", "completed", "Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯");
        }
      } finally {
        setState((prev) => ({ ...prev, lastVideoBlob: null }));
        isExportingRef.current = false;

        setTimeout(() => {
          setState((prev) => {
            const nextIdx = prev.currentQueueIdx + 1;
            const hasNext = prev.isFullPackage && nextIdx < prev.queue.length;
            if (hasNext)
              console.log(
                `\nâ¡ï¸  [AutoPilot] Moving to next documentary (${nextIdx + 1}/${prev.queue.length})\n`,
              );
            else console.log(`\nğŸ [AutoPilot] All documentaries completed!\n`);
            return {
              ...prev,
              currentQueueIdx: hasNext ? nextIdx : -1,
              pipelineStep: "IDLE",
              isAutoMode: hasNext,
              isFullPackage: hasNext,
              isSolving: false,
              isRecording: false,
              progress: 0,
              project: hasNext ? null : prev.project,
            };
          });
        }, 2500);
      }
    },
    [metadata, state.thumbnailDataUrl, state.project, state.storyArc, updateProductionStep],
  );

  useEffect(() => {
    if (state.pipelineStep === "PACKAGING" && state.lastVideoBlob && !isExportingRef.current) {
      executePackaging(state.lastVideoBlob);
    }
  }, [state.pipelineStep, state.lastVideoBlob, executePackaging]);

  // â”€â”€â”€ ğŸ§ª TEST MODE PIPELINE â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

  const processTestModePipeline = useCallback(
    async (item: DocumentaryQueueItem) => {
      console.log("\nğŸ§ª â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");
      console.log("ğŸ§ª TEST MODE ACTIVE - Using sample data (NO AI CALLS)");
      console.log("ğŸ§ª â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n");

      if (!selectedTestProject) {
        setState((s) => ({ ...s, error: "Ù„Ø·ÙØ§Ù‹ Ø§Ø¨ØªØ¯Ø§ ÛŒÚ© Ù¾Ø±ÙˆÚ˜Ù‡ ØªØ³Øª Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯", isGenerating: false }));
        return;
      }

      initProductionSteps();
      setState((s) => ({
        ...s,
        pipelineStep: "SCAN",
        isGenerating: true,
        error: null,
        progress: 0,
        project: null,
        storyArc: null,
        currentChapterIndex: 0,
      }));
      setMetadata(null);

      try {
        // â”€â”€â”€ STEP 1: SCAN (ÙÙˆØ±ÛŒ) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        console.log(`ğŸ§ª [SCAN] Loading test project: "${selectedTestProject.title}"`);
        await new Promise((r) => setTimeout(r, 300));
        updateProductionStep(
          "ğŸ“Š SCAN",
          "completed",
          `TEST: ${selectedTestProject.chapters.length} ÙØµÙ„ â€” ${selectedTestProject.totalDuration}s`,
        );

        // â”€â”€â”€ STEP 2: NARRATIVE (ÙÙˆØ±ÛŒ - Ø§Ø² test data) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        setState((s) => ({ ...s, pipelineStep: "NARRATIVE" }));
        console.log(`ğŸ§ª [NARRATIVE] Using pre-made test narratives`);
        await new Promise((r) => setTimeout(r, 300));
        updateProductionStep(
          "ğŸ“– NARRATIVE",
          "completed",
          `TEST: ${selectedTestProject.chapters.length} ÙØµÙ„ Ø¢Ù…Ø§Ø¯Ù‡`,
        );

        // Ø³Ø§Ø®Øª chapters Ø§Ø² test data
        const roles = assignChapterRoles(selectedTestProject.chapters.length);
        const chapters: Chapter[] = selectedTestProject.chapters.map((testCh, i) => {
          const role = roles[i];
          const complexity = getChapterComplexity(role);
          const pieceCount = getPieceCountForComplexity(complexity, preferences.defaultPieceCount);

          // ğŸ² Ù‡Ø± ÙØµÙ„ Ú©Ø§Ù†ÙÛŒÚ¯ ØªØµØ§Ø¯ÙÛŒ Ø®ÙˆØ¯Ø´ Ø±Ø§ Ù…ÛŒâ€ŒÚ¯ÛŒØ±Ø¯
          const randomConfig = generateRandomPuzzleConfig(pieceCount, complexity);

          return {
            id: `test_ch_${i}`,
            index: i,
            role,
            title: testCh.title,
            narrativeText: testCh.narrativeText,
            imagePrompt: testCh.narrativeText, // Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² narrativeText Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† prompt
            imageUrl: testCh.imageUrl, // âœ… ØªØµÙˆÛŒØ± Ø§Ø² Ù‚Ø¨Ù„ Ø¢Ù…Ø§Ø¯Ù‡ Ø§Ø³Øª
            puzzleConfig: randomConfig,
            durationSeconds: testCh.duration,
            transition: getChapterTransition(role),
            status: ChapterStatus.IMAGE_READY, // âœ… ØªØµÙˆÛŒØ± Ø§Ø² Ù‚Ø¨Ù„ Ø¢Ù…Ø§Ø¯Ù‡ Ø§Ø³Øª
          };
        });

        // â”€â”€â”€ STEP 3: IMAGES (Ø¨Ø§ÛŒâ€ŒÙ¾Ø³ - ØªØµØ§ÙˆÛŒØ± Ø§Ø² Ù‚Ø¨Ù„ Ø¢Ù…Ø§Ø¯Ù‡) â”€â”€â”€â”€â”€â”€â”€
        setState((s) => ({ ...s, pipelineStep: "IMAGES" }));
        console.log(`ğŸ§ª [IMAGES] Images already available in test data - SKIPPING AI generation`);
        await new Promise((r) => setTimeout(r, 500));
        updateProductionStep(
          "ğŸ–¼ï¸ IMAGES",
          "completed",
          `TEST: ${chapters.length}/${chapters.length} ØªØµÙˆÛŒØ± Ø¢Ù…Ø§Ø¯Ù‡ (Ø¨Ø¯ÙˆÙ† AI)`,
        );

        // â”€â”€â”€ STEP 4: MUSIC (Ø¨Ø§ÛŒâ€ŒÙ¾Ø³ ÛŒØ§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø¯Ø³ØªÛŒ) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        setState((s) => ({ ...s, pipelineStep: "MUSIC" }));
        console.log(`ğŸ§ª [MUSIC] Checking for manual music or using test music`);
        await new Promise((r) => setTimeout(r, 300));

        // Ø§Ú¯Ø± Ù…ÙˆØ³ÛŒÙ‚ÛŒ Ø¯Ø³ØªÛŒ Ø¯Ø§Ø±ÛŒÙ… Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ØŒ ÙˆÚ¯Ø±Ù†Ù‡ skip
        const manualTrack = musicTracks.find((t) => t.source === "manual");
        if (manualTrack && audioRef.current) {
          audioRef.current.src = manualTrack.url;
          audioRef.current.load();
          setActiveTrackName(manualTrack.name);
          updateProductionStep("ğŸµ MUSIC", "completed", `Manual: ${manualTrack.name}`);
        } else {
          updateProductionStep("ğŸµ MUSIC", "completed", "TEST: Ø¨Ø¯ÙˆÙ† Ù…ÙˆØ³ÛŒÙ‚ÛŒ");
          musicBufferRef.current = null;
        }

        // â”€â”€â”€ STEP 5: METADATA â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        setState((s) => ({ ...s, pipelineStep: "METADATA" }));
        updateProductionStep("ğŸ“ METADATA", "in_progress");
        setIsMetadataLoading(true);
        await new Promise((r) => setTimeout(r, 300));

        // Ø³Ø§Ø®Øª StoryArc Ø³Ø§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ ØªØ³Øª
        const testStoryArc: StoryArc = {
          hook: selectedTestProject.chapters[0]?.narrativeText || "Test hook",
          buildup: selectedTestProject.chapters[1]?.narrativeText || "Test buildup",
          climax:
            selectedTestProject.chapters[Math.floor(selectedTestProject.chapters.length / 2)]
              ?.narrativeText || "Test climax",
          reveal:
            selectedTestProject.chapters[selectedTestProject.chapters.length - 2]?.narrativeText ||
            "Test reveal",
          conclusion:
            selectedTestProject.chapters[selectedTestProject.chapters.length - 1]?.narrativeText ||
            "Test conclusion",
        };

        const project: DocumentaryProject = {
          id: `test_doc_${Date.now()}`,
          genre: item.genre,
          topic: selectedTestProject.title,
          narrativeLens: item.narrativeLens,
          targetDurationMinutes: Math.floor(selectedTestProject.totalDuration / 60),
          masterVisualStyle: item.masterVisualStyle,
          masterStylePrompt: `Test visual style for ${selectedTestProject.title}`,
          chapters,
          musicTimeline: {
            ambientTrackUrl: audioRef.current?.src || null,
            climaxTrackUrl: null,
            revealTrackUrl: null,
            chapterStingers: [],
          },
          status: ProjectStatus.READY_TO_PLAY,
          createdAt: Date.now(),
        };

        const docMetadata = buildDocumentaryMetadata(project);
        setMetadata(docMetadata);
        setIsMetadataLoading(false);
        updateProductionStep(
          "ğŸ“ METADATA",
          "completed",
          `TEST: ${docMetadata.chapterMarkers.length} markers`,
        );

        // â”€â”€â”€ STEP 6: READY â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        updateProductionStep("ğŸ¬ READY", "completed", "Ø¢Ù…Ø§Ø¯Ù‡ Ù¾Ø®Ø´ (TEST MODE)");

        setState((s) => ({
          ...s,
          project,
          storyArc: testStoryArc,
          docSnippets: chapters.map((ch) => ch.title),
          isGenerating: false,
          pipelineStep: "READY",
        }));

        console.log(`\nğŸ§ª â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•`);
        console.log(`âœ… TEST PROJECT READY: "${project.topic}"`);
        console.log(`   Chapters: ${chapters.length}`);
        console.log(`   Duration: ~${project.targetDurationMinutes} min`);
        console.log(`   All images pre-loaded from test data`);
        console.log(`   NO AI API CALLS WERE MADE`);
        console.log(`ğŸ§ª â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n`);

        // AUTO MODE Ø¯Ø± ØªØ³Øª
        if (state.isAutoMode) {
          updateProductionStep("ğŸ¬ READY", "in_progress", "10s ØµØ¨Ø±... Ø¨Ø¹Ø¯ Ø´Ø±ÙˆØ¹ Ù¾Ø®Ø´ (TEST)");
          setTimeout(() => {
            setState((s) => ({ ...s, isSolving: true, isRecording: true, pipelineStep: "RECORDING" }));
            updateProductionStep("ğŸ¥ RECORD", "in_progress", "Ø¶Ø¨Ø· Ø´Ø±ÙˆØ¹ Ø´Ø¯ (TEST)");
          }, 10000);
        }
      } catch (e) {
        console.error("âŒ [TEST MODE] Error:", e);
        setState((s) => ({
          ...s,
          isGenerating: false,
          isAutoMode: false,
          pipelineStep: "IDLE",
          error: "Test Mode Error â€” Ù„Ø·ÙØ§Ù‹ Ø¯ÙˆØ¨Ø§Ø±Ù‡ Ø³Ø¹ÛŒ Ú©Ù†ÛŒØ¯",
        }));
      }
    },
    [
      selectedTestProject,
      preferences,
      musicTracks,
      audioRef,
      musicBufferRef,
      state.isAutoMode,
      initProductionSteps,
      updateProductionStep,
      setActiveTrackName,
    ],
  );

  // â”€â”€â”€ AI MODE PIPELINE (Ø§ØµÙ„ÛŒ) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

  const processAIModePipeline = useCallback(
    async (item: DocumentaryQueueItem) => {
      console.log("\nğŸ¤– â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");
      console.log("ğŸ¤– AI MODE ACTIVE - Full generation with Gemini");
      console.log("ğŸ¤– â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n");

      initProductionSteps();
      setState((s) => ({
        ...s,
        pipelineStep: "SCAN",
        isGenerating: true,
        error: null,
        progress: 0,
        project: null,
        storyArc: null,
        currentChapterIndex: 0,
      }));
      setMetadata(null);

      try {
        // â”€â”€â”€ STEP 1: SCAN â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        const chapterCount = calcChapterCount(item.targetDurationMinutes);
        console.log(
          `ğŸ“Š [SCAN] Genre: ${item.genre}, Topic: "${item.topic}", Chapters: ${chapterCount}, Duration: ${item.targetDurationMinutes}min`,
        );
        updateProductionStep(
          "ğŸ“Š SCAN",
          "completed",
          `${item.genre} â€” ${chapterCount} ÙØµÙ„ â€” ${item.targetDurationMinutes} Ø¯Ù‚`,
        );

        // â”€â”€â”€ STEP 2: NARRATIVE â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        setState((s) => ({ ...s, pipelineStep: "NARRATIVE" }));
        updateProductionStep("ğŸ“– NARRATIVE", "in_progress", "AI Ø¯Ø§Ø±Ù‡ Ø±ÙˆØ§ÛŒØª Ù…ÛŒØ³Ø§Ø²Ù‡...");

        const narrativeResponse = await generateDocumentaryNarrative(
          item.genre,
          item.topic,
          item.narrativeLens,
          item.targetDurationMinutes,
          item.masterVisualStyle,
        );

        console.log(
          `ğŸ“– [NARRATIVE] Generated ${narrativeResponse.chapters.length} chapters â€” topic: "${narrativeResponse.topic}"`,
        );
        updateProductionStep(
          "ğŸ“– NARRATIVE",
          "completed",
          `${narrativeResponse.chapters.length} ÙØµÙ„ ØªÙˆÙ„ÛŒØ¯ Ø´Ø¯`,
        );

        const roles = assignChapterRoles(narrativeResponse.chapters.length);

        const chapters: Chapter[] = narrativeResponse.chapters.map((nc, i) => {
          const role = roles[i];
          const complexity = getChapterComplexity(role);
          const pieceCount = getPieceCountForComplexity(complexity, preferences.defaultPieceCount);

          // ğŸ² Ù‡Ø± ÙØµÙ„ Ú©Ø§Ù†ÙÛŒÚ¯ ØªØµØ§Ø¯ÙÛŒ Ø®ÙˆØ¯Ø´ Ø±Ø§ Ù…ÛŒâ€ŒÚ¯ÛŒØ±Ø¯
          const randomConfig = generateRandomPuzzleConfig(pieceCount, complexity);

          return {
            id: `ch_${Date.now()}_${i}`,
            index: i,
            role,
            title: nc.title,
            narrativeText: nc.narrativeText,
            imagePrompt: nc.imagePrompt,
            imageUrl: null,
            puzzleConfig: nc.puzzleConfig || randomConfig,
            durationSeconds: 30,
            transition: getChapterTransition(role),
            status: ChapterStatus.PENDING,
          };
        });

        // â”€â”€â”€ STEP 3: IMAGES (batch) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        setState((s) => ({ ...s, pipelineStep: "IMAGES" }));
        updateProductionStep("ğŸ–¼ï¸ IMAGES", "in_progress", "ØªØµØ§ÙˆÛŒØ± ÙØµÙ„â€ŒÙ‡Ø§ Ø¯Ø§Ø±Ù‡ Ø³Ø§Ø®ØªÙ‡ Ù…ÛŒØ´Ù‡...");

        const imageResults = await generateChapterImages(
          chapters,
          narrativeResponse.masterStylePrompt,
          (event: BatchProgressEvent) => {
            if (event.type === "chapter_completed") {
              console.log(`ğŸ–¼ï¸ [IMAGE] ÙØµÙ„ ${event.chapterIndex + 1}/${event.totalChapters} ØªÙ…ÙˆÙ… Ø´Ø¯`);
              updateProductionStep(
                "ğŸ–¼ï¸ IMAGES",
                "in_progress",
                `ÙØµÙ„ ${event.chapterIndex + 1}/${event.totalChapters} ØªØµÙˆÛŒØ± Ø´Ø¯`,
              );
              if (event.imageUrl) {
                chapters[event.chapterIndex].imageUrl = event.imageUrl;
                chapters[event.chapterIndex].status = ChapterStatus.IMAGE_READY;
              }
            }
            if (event.type === "chapter_failed") {
              console.warn(`âš ï¸ [IMAGE] ÙØµÙ„ ${event.chapterIndex + 1} Ø´Ú©Ø³Øª Ø®ÙˆØ±Ø¯`);
            }
          },
        );

        imageResults.results.forEach((r) => {
          if (r.status === "success") {
            chapters[r.chapterIndex].imageUrl = r.imageUrl;
            chapters[r.chapterIndex].status = ChapterStatus.IMAGE_READY;
          }
        });

        console.log(`ğŸ–¼ï¸ [IMAGES] ${imageResults.totalGenerated}/${chapters.length} Ù…ÙˆÙÙ‚`);
        updateProductionStep(
          "ğŸ–¼ï¸ IMAGES",
          "completed",
          `${imageResults.totalGenerated}/${chapters.length} Ù…ÙˆÙÙ‚`,
        );

        // â”€â”€â”€ STEP 4: MUSIC â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        setState((s) => ({ ...s, pipelineStep: "MUSIC" }));
        updateProductionStep("ğŸµ MUSIC", "in_progress", "Ù…ÙˆØ³ÛŒÙ‚ÛŒ ambient Ø¯Ø§Ø±Ù‡ Ù¾ÛŒØ¯Ø§ Ù…ÛŒØ´Ù‡...");

        const ambientMood = detectMusicMoodFromTopic(narrativeResponse.topic, item.narrativeLens);
        const musicResult = await selectSmartMusic({
          musicTracks,
          mood: ambientMood,
          topic: narrativeResponse.topic,
          fetchAudioBlob,
          onAddCloudTrack,
          setActiveTrackName,
          audioRef,
        });

        if (musicResult) {
          updateProductionStep("ğŸµ MUSIC", "completed", `${musicResult.title} (${musicResult.source})`);
          await decodeAndStoreMusicBuffer(audioRef, musicBufferRef, musicResult.blob);
        } else {
          updateProductionStep("ğŸµ MUSIC", "completed", "Ù…ÙˆØ³ÛŒÙ‚ÛŒ Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯ â€” Ø¨Ø¯ÙˆÙ† ØµØ¯Ø§");
          musicBufferRef.current = null;
        }

        // â”€â”€â”€ STEP 5: METADATA â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        setState((s) => ({ ...s, pipelineStep: "METADATA" }));
        updateProductionStep("ğŸ“ METADATA", "in_progress");
        setIsMetadataLoading(true);

        const project: DocumentaryProject = {
          id: `doc_${Date.now()}`,
          genre: item.genre,
          topic: narrativeResponse.topic,
          narrativeLens: item.narrativeLens,
          targetDurationMinutes: item.targetDurationMinutes,
          masterVisualStyle: item.masterVisualStyle,
          masterStylePrompt: narrativeResponse.masterStylePrompt,
          chapters,
          musicTimeline: {
            ambientTrackUrl: audioRef.current?.src || null,
            climaxTrackUrl: null,
            revealTrackUrl: null,
            chapterStingers: [],
          },
          status: ProjectStatus.READY_TO_PLAY,
          createdAt: Date.now(),
        };

        const docMetadata = buildDocumentaryMetadata(project);
        setMetadata(docMetadata);
        setIsMetadataLoading(false);
        updateProductionStep(
          "ğŸ“ METADATA",
          "completed",
          `${docMetadata.chapterMarkers.length} chapter marker`,
        );

        // â”€â”€â”€ STEP 6: READY â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        updateProductionStep("ğŸ¬ READY", "completed", "Ø¢Ù…Ø§Ø¯Ù‡ Ù¾Ø®Ø´");

        setState((s) => ({
          ...s,
          project,
          storyArc: narrativeResponse.storyArc,
          docSnippets: narrativeResponse.keyFacts,
          isGenerating: false,
          pipelineStep: "READY",
        }));

        console.log(`âœ… [PIPELINE] Documentary ready: "${project.topic}" â€” ${chapters.length} ÙØµÙ„`);

        if (state.isAutoMode) {
          updateProductionStep("ğŸ¬ READY", "in_progress", "10s ØµØ¨Ø±... Ø¨Ø¹Ø¯ Ø´Ø±ÙˆØ¹ Ù¾Ø®Ø´");
          setTimeout(() => {
            setState((s) => ({ ...s, isSolving: true, isRecording: true, pipelineStep: "RECORDING" }));
            updateProductionStep("ğŸ¥ RECORD", "in_progress", "Ø¶Ø¨Ø· Ø´Ø±ÙˆØ¹ Ø´Ø¯");
          }, 10000);
        }
      } catch (e) {
        console.error("âŒ [PIPELINE] Error:", e);
        setState((s) => ({
          ...s,
          isGenerating: false,
          isAutoMode: false,
          pipelineStep: "IDLE",
          error: "Pipeline Error â€” Ù„Ø·ÙØ§Ù‹ Ø¯ÙˆØ¨Ø§Ø±Ù‡ Ø³Ø¹ÛŒ Ú©Ù†ÛŒØ¯",
        }));
      }
    },
    [
      preferences,
      musicTracks,
      fetchAudioBlob,
      onAddCloudTrack,
      setActiveTrackName,
      audioRef,
      musicBufferRef,
      state.isAutoMode,
      initProductionSteps,
      updateProductionStep,
    ],
  );

  // â”€â”€â”€ MAIN ROUTER: TEST MODE vs AI MODE â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

  const processPipelineItem = useCallback(
    async (item: DocumentaryQueueItem) => {
      if (isTestMode) {
        await processTestModePipeline(item);
      } else {
        await processAIModePipeline(item);
      }
    },
    [isTestMode, processTestModePipeline, processAIModePipeline],
  );

  // â”€â”€â”€ AUTO PILOT TOGGLE â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

  const toggleAutoMode = useCallback(() => {
    setState((s) => {
      const active = !s.isAutoMode;
      return {
        ...s,
        isAutoMode: active,
        isFullPackage: active,
        pipelineStep: active ? "IDLE" : s.pipelineStep,
        queue: active
          ? [
              {
                genre: ReconstructionGenre.HISTORICAL_RECONSTRUCTION,
                topic: "",
                narrativeLens: NarrativeLens.ORIGIN_STORY,
                masterVisualStyle: MasterVisualStyle.EPIC_PAINTERLY,
                targetDurationMinutes: 8,
              },
              {
                genre: ReconstructionGenre.CRIMINAL_CASEFILE,
                topic: "",
                narrativeLens: NarrativeLens.WHY_MYSTERY,
                masterVisualStyle: MasterVisualStyle.FORENSIC,
                targetDurationMinutes: 10,
              },
              {
                genre: ReconstructionGenre.LOST_CIVILIZATIONS,
                topic: "",
                narrativeLens: NarrativeLens.HIDDEN_DISCOVERY,
                masterVisualStyle: MasterVisualStyle.ARCHAEOLOGICAL,
                targetDurationMinutes: 8,
              },
              {
                genre: ReconstructionGenre.UNSOLVED_MYSTERIES,
                topic: "",
                narrativeLens: NarrativeLens.UNSOLVED_ENIGMA,
                masterVisualStyle: MasterVisualStyle.DARK_DOCUMENTARY,
                targetDurationMinutes: 12,
              },
            ]
          : s.queue,
        currentQueueIdx: active ? 0 : s.currentQueueIdx,
      };
    });
  }, []);

  // â”€â”€â”€ AUTO PILOT LOOP â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

  useEffect(() => {
    if (
      state.isAutoMode &&
      state.pipelineStep === "IDLE" &&
      state.currentQueueIdx >= 0 &&
      state.currentQueueIdx < state.queue.length
    ) {
      processPipelineItem(state.queue[state.currentQueueIdx]);
    }
  }, [state.isAutoMode, state.pipelineStep, state.currentQueueIdx, state.queue, processPipelineItem]);

  // â”€â”€â”€ RETURN â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

  return {
    state,
    setState,
    metadata,
    isMetadataLoading,
    isTestMode, // âœ… Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ø¯Ø± UI
    setThumbnailDataUrl: (url: string | null) => setState((s) => ({ ...s, thumbnailDataUrl: url })),
    setLastVideoBlob: (blob: Blob | null) => setState((s) => ({ ...s, lastVideoBlob: blob })),
    processPipelineItem,
    toggleAutoMode,
  };
};
