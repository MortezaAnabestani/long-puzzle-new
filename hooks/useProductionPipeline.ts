/**
 * Documentary Puzzle Studio â€” Production Pipeline Hook
 *
 * ÙÚ©Ø´Ù† Ø§ØµÙ„ÛŒ: processPipelineItem
 *   SCAN â†’ NARRATIVE â†’ IMAGES (batch) â†’ MUSIC â†’ METADATA â†’ READY
 *
 * Ù…ÙˆÙ†Ø¯Ù†ÛŒ Ø§Ø² Ù‚Ø¨Ù„:
 *   selectSmartMusic, fetchAudioBlob, decodeAndStoreMusicBuffer,
 *   executePackaging, downloadFile, updateProductionStep
 *
 * Ø­Ø°Ù Ø´Ø¯Ù‡:
 *   VIRAL loop, BREAKING loop, similarity check, randomizeVisualParameters,
 *   generateArtImage, YouTubeMetadata, TopicType, MusicSelectionMode,
 *   VIRAL_CATEGORIES, selectFreshCategory, addTopicVariation, getTrendingTopics
 */

import React, { useState, useCallback, useEffect, useRef } from "react";
import {
  PieceShape,
  PieceMaterial,
  MovementType,
  UserPreferences,
  ReconstructionGenre,
  MasterVisualStyle,
  NarrativeLens,
  DocumentaryProject,
  ProjectStatus,
  ChapterStatus,
  StoryArc,
  MusicMood,
  Chapter,
  calcChapterCount,
  assignChapterRoles,
  getChapterComplexity,
  getChapterTransition,
  getPieceCountForComplexity,
} from "../types";
import { generateDocumentaryNarrative, detectMusicMoodFromTopic } from "../services/ai/narrativeEngine";
import { generateChapterImages } from "../services/ai/artGeneration";
import { BatchProgressEvent, DocumentaryMetadata, ChapterMarker } from "../services/types/serviceTypes";
import { MusicTrack } from "../components/sidebar/MusicUploader";
import { contentApi, ContentPayload } from "../services/api/contentApi";
import { sonicEngine } from "../services/proceduralAudio";
import { getJalaliDate } from "../utils/dateUtils";
import { getFolderFromMood } from "../services/ai/musicSelection";

// â”€â”€â”€ TYPES â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

export type PipelineStep =
  | "IDLE"
  | "SCAN"
  | "NARRATIVE"
  | "IMAGES"
  | "MUSIC"
  | "METADATA"
  | "READY"
  | "RECORDING"
  | "PACKAGING";

export interface ProductionStep {
  id: string;
  label: string;
  status: "pending" | "in_progress" | "completed" | "error";
  details?: string;
}

/** Ù‚ÛŒØªÙ… ØµÙˆØ±Øªâ€ŒØµÙˆØ±Øª auto-pilot ÛŒØ§ Ø¯Ø³ØªÛŒ */
export interface DocumentaryQueueItem {
  genre: ReconstructionGenre;
  topic: string; // Ø®Ø§Ù„ÛŒ â†’ AI Ù…ÙˆØ¶ÙˆØ¹ Ù…ÛŒØ¯Ù‡
  narrativeLens: NarrativeLens;
  masterVisualStyle: MasterVisualStyle;
  targetDurationMinutes: number; // 8 | 10 | 12 | 15
}

export interface PipelineState {
  project: DocumentaryProject | null;
  currentChapterIndex: number;
  isGenerating: boolean;
  isSolving: boolean;
  isRecording: boolean;
  progress: number;
  error: string | null;
  audioError: boolean;
  isAutoMode: boolean;
  isFullPackage: boolean;
  queue: DocumentaryQueueItem[];
  currentQueueIdx: number;
  pipelineStep: PipelineStep;
  productionSteps: ProductionStep[];
  storyArc: StoryArc | null;
  docSnippets: string[]; // keyFacts Ø§Ø² narrative
  lastVideoBlob: Blob | null;
  thumbnailDataUrl: string | null;
}

// â”€â”€â”€ CLOUDFLARE PROXY â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

const CLOUDFLARE_WORKER_URL = "https://plain-tooth-75c3.jujube-bros.workers.dev/";

// â”€â”€â”€ AUDIO HELPERS (Ù…ÙˆÙ†Ø¯Ù†ÛŒØŒ Ø¯Ø³Øªâ€ŒÙ†Ø®ÙˆØ±Ø¯Ù‡) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

const decodeAndStoreMusicBuffer = async (
  audioRef: React.RefObject<HTMLAudioElement | null>,
  musicBufferRef: React.MutableRefObject<AudioBuffer | null>,
  blobOrNull?: Blob | null
): Promise<void> => {
  const ctx = sonicEngine.getContext();
  if (!ctx) {
    console.warn("âš ï¸ [MUSIC] No AudioContext for decode");
    return;
  }

  let arrayBuffer: ArrayBuffer;
  if (blobOrNull && blobOrNull.size > 0 && !blobOrNull.type.startsWith("text/")) {
    try {
      arrayBuffer = await blobOrNull.arrayBuffer();
    } catch (e) {
      console.warn("âš ï¸ [MUSIC] Blob.arrayBuffer() failed:", e);
      return;
    }
  } else {
    const el = audioRef.current;
    const url = el?.src || el?.currentSrc;
    if (!url || url === "" || url === "about:blank") return;
    try {
      const res = await fetch(url);
      if (!res.ok) throw new Error(`Fetch ${res.status}`);
      const blob = await res.blob();
      if (blob.size === 0 || blob.type.startsWith("text/")) {
        console.warn(`âš ï¸ [MUSIC] Fetched response is not audio (size=${blob.size}, type=${blob.type})`);
        return;
      }
      arrayBuffer = await blob.arrayBuffer();
    } catch (e) {
      console.warn("âš ï¸ [MUSIC] Fetch for decode failed:", e);
      return;
    }
  }

  try {
    const decoded = await ctx.decodeAudioData(arrayBuffer.slice(0));
    musicBufferRef.current = decoded;
    console.log(`ğŸµ [MUSIC] Decoded to AudioBuffer (${(decoded.length / decoded.sampleRate).toFixed(1)}s)`);
  } catch (e) {
    console.warn("âš ï¸ [MUSIC] Decode failed (keeping previous buffer):", e);
  }
};

// â”€â”€â”€ SMART MUSIC (Ù…ÙˆÙ†Ø¯Ù†ÛŒØŒ ÙÙ‚Ø· MusicSelectionMode Ø­Ø°Ù Ø´Ø¯ â€” backend+AI fallback) â”€

interface SmartMusicParams {
  musicTracks: MusicTrack[];
  mood: MusicMood;
  topic: string;
  fetchAudioBlob: (url: string) => Promise<{ url: string; blob: Blob } | null>;
  onAddCloudTrack: (url: string, title: string, source?: "backend" | "ai") => void;
  setActiveTrackName: (name: string | null) => void;
  audioRef: React.RefObject<HTMLAudioElement | null>;
}

const selectSmartMusic = async (
  params: SmartMusicParams
): Promise<{ source: string; title: string; blob?: Blob } | null> => {
  const { musicTracks, mood, topic, fetchAudioBlob, onAddCloudTrack, setActiveTrackName, audioRef } = params;

  // Priority 1: Ø¯Ø³ØªÛŒ
  const manual = musicTracks.filter((t) => t.source === "manual");
  if (manual.length > 0) {
    const track = manual[0];
    if (audioRef.current) {
      audioRef.current.src = track.url;
      audioRef.current.load();
    }
    setActiveTrackName(track.name);
    console.log(`ğŸµ [MUSIC] Manual: ${track.name}`);
    return { source: "Manual Upload", title: track.name };
  }

  // Priority 2: Backend database
  let trackData: { title: string; url: string; source: string } | null = null;
  try {
    const { assetApi } = await import("../services/api/assetApi");
    const folderName = getFolderFromMood(mood);
    console.log(`ğŸµ [MUSIC] Backend search: folder=${folderName}`);
    const backendUrl = await assetApi.getRandomMusicByMood(folderName);
    if (backendUrl) trackData = { title: `${mood} (Database)`, url: backendUrl, source: "Backend Database" };

    if (!trackData) {
      const fallback = await assetApi.getRandomMusicByMood("calm");
      if (fallback) trackData = { title: "Calm (Fallback)", url: fallback, source: "Backend Database" };
    }
  } catch (e) {
    console.warn("âš ï¸ [MUSIC] Backend search failed:", e);
  }

  // Priority 3: AI search
  if (!trackData) {
    try {
      const { findSmartMusicByMood } = await import("../services/geminiService");
      trackData = await findSmartMusicByMood(mood, topic);
    } catch (e) {
      console.warn("âš ï¸ [MUSIC] AI search failed:", e);
    }
  }

  if (trackData?.url) {
    const result = await fetchAudioBlob(trackData.url);
    if (result) {
      const sourceType = trackData.source === "Backend Database" ? "backend" : "ai";
      onAddCloudTrack(result.url, trackData.title, sourceType);
      setActiveTrackName(trackData.title);
      if (audioRef.current) {
        audioRef.current.src = result.url;
        audioRef.current.load();
      }
      console.log(`ğŸµ [MUSIC] Selected: ${trackData.title}`);
      return { source: trackData.source, title: trackData.title, blob: result.blob };
    }
  }

  console.warn("âš ï¸ [MUSIC] No music found");
  return null;
};

// â”€â”€â”€ CHAPTER MARKERS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

const buildChapterMarkers = (chapters: Chapter[]): ChapterMarker[] => {
  let totalSeconds = 0;
  return chapters.map((ch) => {
    const mins = Math.floor(totalSeconds / 60);
    const secs = totalSeconds % 60;
    const timestamp = `${mins}:${secs.toString().padStart(2, "0")}`;
    totalSeconds += ch.durationSeconds;
    return { timestamp, title: ch.title };
  });
};

// â”€â”€â”€ METADATA BUILDER â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

const buildDocumentaryMetadata = (project: DocumentaryProject): DocumentaryMetadata => {
  const markers = buildChapterMarkers(project.chapters);
  const chapterList = project.chapters.map((ch, i) => `ÙØµÙ„ ${i + 1}: ${ch.title}`).join("\n");

  return {
    title: `ğŸ” ${project.topic} â€” ${project.genre} Documentary`,
    description: `ÛŒÚ© documentary ${project.targetDurationMinutes}-Ø¯Ù‚ÛŒÙ‚Ù‡â€ŒØ§ÛŒ Ø¯Ø±Ø¨Ø§Ø±Ù‡ ${project.topic}\n\n${chapterList}\n\nAuto-generated by Documentary Puzzle Studio`,
    tags: [project.genre, project.topic, "documentary", "puzzle", "history", "mystery", "longform"],
    hashtags: ["#documentary", "#puzzle", "#mystery", "#longform", "#history"],
    ctr_strategy: `Ø¹Ù†ÙˆØ§Ù† Ø´ÙˆÚ©â€ŒØ¯Ù‡Ù†Ø¯Ù‡ + ÙØµÙ„â€ŒØ¨Ù†Ø¯ÛŒ ÙˆØ§Ø¶Ø­ + chapter markers`,
    chapterMarkers: markers,
  };
};

// â”€â”€â”€ HOOK â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

export const useProductionPipeline = (
  preferences: UserPreferences,
  setPreferences: React.Dispatch<React.SetStateAction<UserPreferences>>,
  musicTracks: MusicTrack[],
  selectedTrackId: string | null,
  setActiveTrackName: (name: string | null) => void,
  onAddCloudTrack: (url: string, title: string, source?: "backend" | "ai") => void,
  audioRef: React.RefObject<HTMLAudioElement | null>,
  musicBufferRef: React.MutableRefObject<AudioBuffer | null>
) => {
  const [state, setState] = useState<PipelineState>({
    project: null,
    currentChapterIndex: 0,
    isGenerating: false,
    isSolving: false,
    isRecording: false,
    progress: 0,
    error: null,
    audioError: false,
    isAutoMode: false,
    isFullPackage: false,
    queue: [],
    currentQueueIdx: -1,
    pipelineStep: "IDLE",
    productionSteps: [],
    storyArc: null,
    docSnippets: [],
    lastVideoBlob: null,
    thumbnailDataUrl: null,
  });

  const [metadata, setMetadata] = useState<DocumentaryMetadata | null>(null);
  const [isMetadataLoading, setIsMetadataLoading] = useState(false);
  const isExportingRef = useRef(false);

  // â”€â”€â”€ STEP HELPERS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

  const updateProductionStep = useCallback(
    (stepId: string, status: ProductionStep["status"], details?: string) => {
      setState((prev) => {
        const idx = prev.productionSteps.findIndex((s) => s.id === stepId);
        if (idx >= 0) {
          const steps = [...prev.productionSteps];
          steps[idx] = { ...steps[idx], status, details: details || steps[idx].details };
          return { ...prev, productionSteps: steps };
        }
        return {
          ...prev,
          productionSteps: [...prev.productionSteps, { id: stepId, label: stepId, status, details }],
        };
      });
    },
    []
  );

  const initProductionSteps = useCallback(() => {
    setState((prev) => ({
      ...prev,
      productionSteps: [
        { id: "ğŸ“Š SCAN", label: "Ø´Ø±ÙˆØ¹ Ù¾Ø±ÙˆÚ˜Ù‡", status: "pending" },
        { id: "ğŸ“– NARRATIVE", label: "ØªÙˆÙ„ÛŒØ¯ Ø±ÙˆØ§ÛŒØª ÙØµÙ„â€ŒÙ‡Ø§", status: "pending" },
        { id: "ğŸ–¼ï¸ IMAGES", label: "ØªÙˆÙ„ÛŒØ¯ ØªØµØ§ÙˆÛŒØ± batch", status: "pending" },
        { id: "ğŸµ MUSIC", label: "Ø§Ù†ØªØ®Ø§Ø¨ Ù…ÙˆØ³ÛŒÙ‚ÛŒ", status: "pending" },
        { id: "ğŸ“ METADATA", label: "Ù…ØªØ§Ø¯ÛŒØªØ§ Ùˆ ÙØµÙ„â€ŒØ¨Ù†Ø¯ÛŒ", status: "pending" },
        { id: "ğŸ¬ READY", label: "Ø¢Ù…Ø§Ø¯Ù‡ Ù¾Ø®Ø´", status: "pending" },
        { id: "ğŸ¥ RECORD", label: "Ø¶Ø¨Ø· ÙˆÛŒØ¯Ø¦Ùˆ", status: "pending" },
        { id: "ğŸ“¦ PACKAGE", label: "Ø¯Ø§Ù†Ù„ÙˆØ¯ Ùˆ Ø°Ø®ÛŒØ±Ù‡", status: "pending" },
      ],
    }));
  }, []);

  // â”€â”€â”€ FETCH AUDIO BLOB (Ù…ÙˆÙ†Ø¯Ù†ÛŒ) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

  const fetchAudioBlob = useCallback(async (url: string): Promise<{ url: string; blob: Blob } | null> => {
    const proxies = [
      `${CLOUDFLARE_WORKER_URL}?url=${encodeURIComponent(url)}`,
      `https://api.allorigins.win/raw?url=${encodeURIComponent(url)}`,
    ];
    for (const p of proxies) {
      try {
        const res = await fetch(p);
        if (res.ok) {
          let blob = await res.blob();
          if (!blob.type || blob.type === "application/octet-stream")
            blob = new Blob([blob], { type: "audio/mpeg" });
          console.log(`âœ… [fetchAudioBlob] size=${(blob.size / 1024).toFixed(1)}KB`);
          return { url: URL.createObjectURL(blob), blob };
        }
      } catch {
        /* next */
      }
    }
    console.error("âŒ [fetchAudioBlob] All proxies failed");
    return null;
  }, []);

  // â”€â”€â”€ DOWNLOAD â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

  const downloadFile = (name: string, blob: Blob) => {
    const url = URL.createObjectURL(blob);
    const link = document.createElement("a");
    link.href = url;
    link.download = name;
    document.body.appendChild(link);
    link.click();
    document.body.removeChild(link);
    setTimeout(() => URL.revokeObjectURL(url), 3000);
  };

  // â”€â”€â”€ PACKAGING (Ù…ÙˆÙ†Ø¯Ù†ÛŒØŒ metadata Ø´Ú©Ù„Ø´ Ø¹ÙˆØ¶ Ø´Ø¯) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

  const executePackaging = useCallback(
    async (videoBlob: Blob) => {
      if (isExportingRef.current) return;
      isExportingRef.current = true;

      const jalali = getJalaliDate();
      const cleanTitle = (metadata?.title || "Documentary").replace(/[\\/:*?"<>|]/g, "").slice(0, 50);
      const base = `${jalali}_${cleanTitle}`;

      updateProductionStep("ğŸ“¦ PACKAGE", "in_progress", "Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø´Ø±ÙˆØ¹ Ø´Ø¯...");

      try {
        // â”€â”€ ÙˆÛŒØ¯Ø¦Ùˆ â”€â”€
        downloadFile(`${base}_Video.${videoBlob.type.includes("mp4") ? "mp4" : "webm"}`, videoBlob);

        // â”€â”€ metadata (Ø´Ø§Ù…Ù„ chapter markers) â”€â”€
        if (metadata) {
          await new Promise((r) => setTimeout(r, 1500));
          const markerText = metadata.chapterMarkers.map((m) => `${m.timestamp} - ${m.title}`).join("\n");
          downloadFile(
            `${base}_Metadata.txt`,
            new Blob(
              [
                `TITLE: ${metadata.title}\n\nDESC:\n${
                  metadata.description
                }\n\nCHAPTER MARKERS:\n${markerText}\n\nTAGS: ${metadata.tags.join(
                  ", "
                )}\n\nHASHTAGS: ${metadata.hashtags.join(" ")}`,
              ],
              { type: "text/plain" }
            )
          );
        }

        // â”€â”€ ØªØ§Ù…Ø¨Ù†ÛŒÙ„ â”€â”€
        if (state.thumbnailDataUrl) {
          await new Promise((r) => setTimeout(r, 1500));
          const res = await fetch(state.thumbnailDataUrl);
          downloadFile(`${base}_Thumbnail.jpg`, await res.blob());
        }

        // â”€â”€ Ø°Ø®ÛŒØ±Ù‡ Ø¯ÛŒØªØ§Ø¨ÛŒØ³ â”€â”€
        if (metadata && state.project && state.storyArc) {
          try {
            const payload: ContentPayload = {
              jalaliDate: jalali,
              puzzleCard: {
                source: "DOCUMENTARY",
                category: state.project.genre,
                narrativeLens: state.project.narrativeLens,
                duration: state.project.targetDurationMinutes,
              },
              story: {
                coreSubject: state.project.topic,
                hook: state.storyArc.hook,
                buildup: state.storyArc.buildup,
                climax: state.storyArc.climax,
                reveal: state.storyArc.reveal,
                conclusion: state.storyArc.conclusion,
              },
              metadata: {
                title: metadata.title,
                description: metadata.description,
                tags: metadata.tags,
                hashtags: metadata.hashtags,
              },
              files: {
                videoFilename: `${base}_Video.${videoBlob.type.includes("mp4") ? "mp4" : "webm"}`,
                videoSizeMB: Number((videoBlob.size / 1024 / 1024).toFixed(2)),
              },
            };
            const result = await contentApi.saveContent(payload);
            if (result.success) {
              console.log(`âœ… [DB] Saved â€” ID: ${result.data?._id}`);
              updateProductionStep(
                "ğŸ“¦ PACKAGE",
                "completed",
                `Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯ â€” ID: ${result.data?._id?.substring(0, 8)}...`
              );
            } else {
              updateProductionStep("ğŸ“¦ PACKAGE", "completed", "Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯ â€” Ø®Ø·Ø§ Ø¯Ø± Ø°Ø®ÛŒØ±Ù‡ DB");
            }
          } catch {
            updateProductionStep("ğŸ“¦ PACKAGE", "completed", "Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯ â€” DB skip");
          }
        } else {
          updateProductionStep("ğŸ“¦ PACKAGE", "completed", "Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯");
        }
      } finally {
        setState((prev) => ({ ...prev, lastVideoBlob: null }));
        isExportingRef.current = false;

        // â”€â”€ queue Ø¨Ø¹Ø¯ÛŒÙ‡ØŸ â”€â”€
        setTimeout(() => {
          setState((prev) => {
            const nextIdx = prev.currentQueueIdx + 1;
            const hasNext = prev.isFullPackage && nextIdx < prev.queue.length;
            if (hasNext)
              console.log(
                `\nâ¡ï¸  [AutoPilot] Moving to next documentary (${nextIdx + 1}/${prev.queue.length})\n`
              );
            else console.log(`\nğŸ [AutoPilot] All documentaries completed!\n`);
            return {
              ...prev,
              currentQueueIdx: hasNext ? nextIdx : -1,
              pipelineStep: "IDLE",
              isAutoMode: hasNext,
              isFullPackage: hasNext,
              isSolving: false,
              isRecording: false,
              progress: 0,
              project: hasNext ? null : prev.project,
            };
          });
        }, 2500);
      }
    },
    [metadata, state.thumbnailDataUrl, state.project, state.storyArc, updateProductionStep]
  );

  // packaging trigger
  useEffect(() => {
    if (state.pipelineStep === "PACKAGING" && state.lastVideoBlob && !isExportingRef.current) {
      executePackaging(state.lastVideoBlob);
    }
  }, [state.pipelineStep, state.lastVideoBlob, executePackaging]);

  // â”€â”€â”€ MAIN PIPELINE â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

  const processPipelineItem = useCallback(
    async (item: DocumentaryQueueItem) => {
      initProductionSteps();
      setState((s) => ({
        ...s,
        pipelineStep: "SCAN",
        isGenerating: true,
        error: null,
        progress: 0,
        project: null,
        storyArc: null,
        currentChapterIndex: 0,
      }));
      setMetadata(null);

      try {
        // â”€â”€â”€ STEP 1: SCAN â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        const chapterCount = calcChapterCount(item.targetDurationMinutes);
        console.log(
          `ğŸ“Š [SCAN] Genre: ${item.genre}, Topic: "${item.topic}", Chapters: ${chapterCount}, Duration: ${item.targetDurationMinutes}min`
        );
        updateProductionStep(
          "ğŸ“Š SCAN",
          "completed",
          `${item.genre} â€” ${chapterCount} ÙØµÙ„ â€” ${item.targetDurationMinutes} Ø¯Ù‚`
        );

        // â”€â”€â”€ STEP 2: NARRATIVE â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        setState((s) => ({ ...s, pipelineStep: "NARRATIVE" }));
        updateProductionStep("ğŸ“– NARRATIVE", "in_progress", "AI Ø¯Ø§Ø±Ù‡ Ø±ÙˆØ§ÛŒØª Ù…ÛŒØ³Ø§Ø²Ù‡...");

        const narrativeResponse = await generateDocumentaryNarrative(
          item.genre,
          item.topic,
          item.narrativeLens,
          item.targetDurationMinutes,
          item.masterVisualStyle
        );

        console.log(
          `ğŸ“– [NARRATIVE] Generated ${narrativeResponse.chapters.length} chapters â€” topic: "${narrativeResponse.topic}"`
        );
        updateProductionStep(
          "ğŸ“– NARRATIVE",
          "completed",
          `${narrativeResponse.chapters.length} ÙØµÙ„ ØªÙˆÙ„ÛŒØ¯ Ø´Ø¯`
        );

        // â”€â”€â”€ ÙØµÙ„â€ŒÙ‡Ø§ Ø±Ùˆ Chapter objects Ø¨Ø³Ø§Ø²ÛŒÙ… â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        const roles = assignChapterRoles(narrativeResponse.chapters.length);

        const chapters: Chapter[] = narrativeResponse.chapters.map((nc, i) => {
          const role = roles[i];
          const complexity = getChapterComplexity(role);
          const pieceCount = getPieceCountForComplexity(complexity, preferences.defaultPieceCount);

          return {
            id: `ch_${Date.now()}_${i}`,
            index: i,
            role,
            title: nc.title,
            narrativeText: nc.narrativeText,
            imagePrompt: nc.imagePrompt,
            imageUrl: null,
            puzzleConfig: nc.puzzleConfig || {
              pieceCount,
              shape: preferences.defaultShape,
              material: preferences.defaultMaterial,
              movement: preferences.defaultMovement,
              complexityLevel: complexity,
            },
            durationSeconds: 45,
            transition: getChapterTransition(role),
            status: ChapterStatus.PENDING,
          };
        });

        // â”€â”€â”€ STEP 3: IMAGES (batch) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        setState((s) => ({ ...s, pipelineStep: "IMAGES" }));
        updateProductionStep("ğŸ–¼ï¸ IMAGES", "in_progress", "ØªØµØ§ÙˆÛŒØ± ÙØµÙ„â€ŒÙ‡Ø§ Ø¯Ø§Ø±Ù‡ Ø³Ø§Ø®ØªÙ‡ Ù…ÛŒØ´Ù‡...");

        const imageResults = await generateChapterImages(
          chapters,
          narrativeResponse.masterStylePrompt,
          (event: BatchProgressEvent) => {
            if (event.type === "chapter_completed") {
              console.log(`ğŸ–¼ï¸ [IMAGE] ÙØµÙ„ ${event.chapterIndex + 1}/${event.totalChapters} ØªÙ…ÙˆÙ… Ø´Ø¯`);
              updateProductionStep(
                "ğŸ–¼ï¸ IMAGES",
                "in_progress",
                `ÙØµÙ„ ${event.chapterIndex + 1}/${event.totalChapters} ØªØµÙˆÛŒØ± Ø´Ø¯`
              );
              // imageUrl local update â€” imageResults.results Ø¨Ø¹Ø¯Ø§Ù‹ Ú©Ø§Ù…Ù„ Ù…ÛŒØ´Ù‡
              if (event.imageUrl) {
                chapters[event.chapterIndex].imageUrl = event.imageUrl;
                chapters[event.chapterIndex].status = ChapterStatus.IMAGE_READY;
              }
            }
            if (event.type === "chapter_failed") {
              console.warn(`âš ï¸ [IMAGE] ÙØµÙ„ ${event.chapterIndex + 1} Ø´Ú©Ø³Øª Ø®ÙˆØ±Ø¯`);
            }
          }
        );

        // Ù†ØªÛŒØ¬Ù‡â€ŒÙ‡Ø§ÛŒ batch Ø§Ø¹Ù…Ø§Ù„
        imageResults.results.forEach((r) => {
          if (r.status === "success") {
            chapters[r.chapterIndex].imageUrl = r.imageUrl;
            chapters[r.chapterIndex].status = ChapterStatus.IMAGE_READY;
          }
        });

        console.log(`ğŸ–¼ï¸ [IMAGES] ${imageResults.totalGenerated}/${chapters.length} Ù…ÙˆÙÙ‚`);
        updateProductionStep(
          "ğŸ–¼ï¸ IMAGES",
          "completed",
          `${imageResults.totalGenerated}/${chapters.length} Ù…ÙˆÙÙ‚`
        );

        // â”€â”€â”€ STEP 4: MUSIC â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        setState((s) => ({ ...s, pipelineStep: "MUSIC" }));
        updateProductionStep("ğŸµ MUSIC", "in_progress", "Ù…ÙˆØ³ÛŒÙ‚ÛŒ ambient Ø¯Ø§Ø±Ù‡ Ù¾ÛŒØ¯Ø§ Ù…ÛŒØ´Ù‡...");

        const ambientMood = detectMusicMoodFromTopic(narrativeResponse.topic, item.narrativeLens);
        const musicResult = await selectSmartMusic({
          musicTracks,
          mood: ambientMood,
          topic: narrativeResponse.topic,
          fetchAudioBlob,
          onAddCloudTrack,
          setActiveTrackName,
          audioRef,
        });

        if (musicResult) {
          updateProductionStep("ğŸµ MUSIC", "completed", `${musicResult.title} (${musicResult.source})`);
          await decodeAndStoreMusicBuffer(audioRef, musicBufferRef, musicResult.blob);
        } else {
          updateProductionStep("ğŸµ MUSIC", "completed", "Ù…ÙˆØ³ÛŒÙ‚ÛŒ Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯ â€” Ø¨Ø¯ÙˆÙ† ØµØ¯Ø§");
          musicBufferRef.current = null;
        }

        // â”€â”€â”€ STEP 5: METADATA â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        setState((s) => ({ ...s, pipelineStep: "METADATA" }));
        updateProductionStep("ğŸ“ METADATA", "in_progress");
        setIsMetadataLoading(true);

        const project: DocumentaryProject = {
          id: `doc_${Date.now()}`,
          genre: item.genre,
          topic: narrativeResponse.topic,
          narrativeLens: item.narrativeLens,
          targetDurationMinutes: item.targetDurationMinutes,
          masterVisualStyle: item.masterVisualStyle,
          masterStylePrompt: narrativeResponse.masterStylePrompt,
          chapters,
          musicTimeline: {
            ambientTrackUrl: audioRef.current?.src || null,
            climaxTrackUrl: null, // Round 4
            revealTrackUrl: null, // Round 4
            chapterStingers: [],
          },
          status: ProjectStatus.READY_TO_PLAY,
          createdAt: Date.now(),
        };

        const docMetadata = buildDocumentaryMetadata(project);
        setMetadata(docMetadata);
        setIsMetadataLoading(false);
        updateProductionStep(
          "ğŸ“ METADATA",
          "completed",
          `${docMetadata.chapterMarkers.length} chapter marker`
        );

        // â”€â”€â”€ STEP 6: READY â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        updateProductionStep("ğŸ¬ READY", "completed", "Ø¢Ù…Ø§Ø¯Ù‡ Ù¾Ø®Ø´");

        setState((s) => ({
          ...s,
          project,
          storyArc: narrativeResponse.storyArc,
          docSnippets: narrativeResponse.keyFacts,
          isGenerating: false,
          pipelineStep: "READY",
        }));

        console.log(`âœ… [PIPELINE] Documentary ready: "${project.topic}" â€” ${chapters.length} ÙØµÙ„`);

        // â”€â”€â”€ AUTO MODE: 10s ØµØ¨Ø± Ø¨Ø¹Ø¯ Ù¾Ø®Ø´ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        if (state.isAutoMode) {
          updateProductionStep("ğŸ¬ READY", "in_progress", "10s ØµØ¨Ø±... Ø¨Ø¹Ø¯ Ø´Ø±ÙˆØ¹ Ù¾Ø®Ø´");
          setTimeout(() => {
            setState((s) => ({ ...s, isSolving: true, isRecording: true, pipelineStep: "RECORDING" }));
            updateProductionStep("ğŸ¥ RECORD", "in_progress", "Ø¶Ø¨Ø· Ø´Ø±ÙˆØ¹ Ø´Ø¯");
          }, 10000);
        }
      } catch (e) {
        console.error("âŒ [PIPELINE] Error:", e);
        setState((s) => ({
          ...s,
          isGenerating: false,
          isAutoMode: false,
          pipelineStep: "IDLE",
          error: "Pipeline Error â€” Ù„Ø·ÙØ§Ù‹ Ø¯ÙˆØ¨Ø§Ø±Ù‡ Ø³Ø¹ÛŒ Ú©Ù†ÛŒØ¯",
        }));
      }
    },
    [
      preferences,
      musicTracks,
      fetchAudioBlob,
      onAddCloudTrack,
      setActiveTrackName,
      audioRef,
      musicBufferRef,
      state.isAutoMode,
      initProductionSteps,
      updateProductionStep,
    ]
  );

  // â”€â”€â”€ AUTO PILOT TOGGLE â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

  const toggleAutoMode = useCallback(() => {
    setState((s) => {
      const active = !s.isAutoMode;
      return {
        ...s,
        isAutoMode: active,
        isFullPackage: active,
        pipelineStep: active ? "IDLE" : s.pipelineStep,
        queue: active
          ? [
              {
                genre: ReconstructionGenre.HISTORICAL_RECONSTRUCTION,
                topic: "",
                narrativeLens: NarrativeLens.ORIGIN_STORY,
                masterVisualStyle: MasterVisualStyle.EPIC_PAINTERLY,
                targetDurationMinutes: 8,
              },
              {
                genre: ReconstructionGenre.CRIMINAL_CASEFILE,
                topic: "",
                narrativeLens: NarrativeLens.WHY_MYSTERY,
                masterVisualStyle: MasterVisualStyle.FORENSIC,
                targetDurationMinutes: 10,
              },
              {
                genre: ReconstructionGenre.LOST_CIVILIZATIONS,
                topic: "",
                narrativeLens: NarrativeLens.HIDDEN_DISCOVERY,
                masterVisualStyle: MasterVisualStyle.ARCHAEOLOGICAL,
                targetDurationMinutes: 8,
              },
              {
                genre: ReconstructionGenre.UNSOLVED_MYSTERIES,
                topic: "",
                narrativeLens: NarrativeLens.UNSOLVED_ENIGMA,
                masterVisualStyle: MasterVisualStyle.DARK_DOCUMENTARY,
                targetDurationMinutes: 12,
              },
            ]
          : s.queue,
        currentQueueIdx: active ? 0 : s.currentQueueIdx,
      };
    });
  }, []);

  // â”€â”€â”€ AUTO PILOT LOOP â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

  useEffect(() => {
    if (
      state.isAutoMode &&
      state.pipelineStep === "IDLE" &&
      state.currentQueueIdx >= 0 &&
      state.currentQueueIdx < state.queue.length
    ) {
      processPipelineItem(state.queue[state.currentQueueIdx]);
    }
  }, [state.isAutoMode, state.pipelineStep, state.currentQueueIdx, state.queue, processPipelineItem]);

  // â”€â”€â”€ RETURN â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

  return {
    state,
    setState,
    metadata,
    isMetadataLoading,
    setThumbnailDataUrl: (url: string | null) => setState((s) => ({ ...s, thumbnailDataUrl: url })),
    setLastVideoBlob: (blob: Blob | null) => setState((s) => ({ ...s, lastVideoBlob: blob })),
    processPipelineItem,
    toggleAutoMode,
  };
};
